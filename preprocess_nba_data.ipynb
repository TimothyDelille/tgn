{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process basic_stats\n",
    "basic_stats = pd.read_csv('/Volumes/TOSHIBA EXT TIMOTHY DELILLE/GitHub/fantasy-nba/data/basic_stats.csv')\n",
    "basic_stats.dropna(subset=['game_id', 'player_id'], inplace=True)\n",
    "\n",
    "# convert minutes played to actual number of minutes\n",
    "basic_stats['mp'] = basic_stats[\"mp\"].str.split(\":\")\\\n",
    "                                     .fillna(\"00\")\\\n",
    "                                     .apply(lambda x: sum([int(x[-k - 1])/(60**(len(x) - k - 1)) \n",
    "                                                           for k in range(len(x))]))\n",
    "\n",
    "# is starter?\n",
    "basic_stats['is_starter'] = basic_stats['type'] == 'Starter'\n",
    "\n",
    "# one hot vector encoding of team names\n",
    "abbreviations = pd.read_csv('/Volumes/TOSHIBA EXT TIMOTHY DELILLE/GitHub/fantasy-nba/data/abbreviations.csv')\n",
    "\n",
    "basic_stats['team'] = basic_stats['team'].replace({'CHA': 'CHO'})\n",
    "\n",
    "assert basic_stats['team'].isin(abbreviations['basketball_reference_abbreviation']).all(),\\\n",
    "      'Some team names in basic_stats are not basketball reference abbreviations'\n",
    "\n",
    "for team in abbreviations['basketball_reference_abbreviation']:\n",
    "    basic_stats[team] = basic_stats['team'] == team\n",
    "\n",
    "# add info about the game\n",
    "schedules = pd.read_csv('/Volumes/TOSHIBA EXT TIMOTHY DELILLE/GitHub/fantasy-nba/data/schedules.csv')\n",
    "schedules.dropna(subset=['game_id'], inplace=True)\n",
    "\n",
    "assert schedules['game_id'].is_unique, 'Duplicate game_id in schedules'\n",
    "\n",
    "basic_stats = pd.merge(basic_stats, schedules, on='game_id', how='left')\n",
    "basic_stats['reason'] = basic_stats['reason'].replace({'\\xa0', ''})\n",
    "\n",
    "# convert date and time to datetime objects\n",
    "basic_stats['date'] = pd.to_datetime(basic_stats['date']).dt.date\n",
    "basic_stats['time'] = pd.to_datetime(basic_stats['time']).dt.time\n",
    "# combine date and time into datetime\n",
    "basic_stats['datetime'] = basic_stats.apply(lambda row: pd.Timestamp.combine(row['date'], row['time']), axis=1)\n",
    "# convert datetime to unix timestamp\n",
    "basic_stats['timestamp'] = (basic_stats['datetime'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "# is the game taking place at home?\n",
    "basic_stats['is_at_home'] = basic_stats['HOME'] == basic_stats['team']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ids = basic_stats['player_id'].dropna().unique()\n",
    "tag2id = {tag: id for id, tag in enumerate(player_ids)} # start at 1\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dk_pts(features):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred_features: tensor of shape (-1, num labels) in this specific order\n",
    "                       pts, fg3, orb, ast, stl, blk, tov\n",
    "    \"\"\"\n",
    "    # inputs are tensors of shape (num players,)\n",
    "    # double-double: max 1 per player, Points, Rebounds, Assists, Blocks, Steals\n",
    "    # triple-double: max 1 per player, Points, Rebounds, Assists, Blocks, Steals\n",
    "\n",
    "    factors = torch.tensor([1, 0.5, 1.25, 1.5, 2, 2, -0.5])\n",
    "\n",
    "    # ids used in the double-double or triple-double calculations\n",
    "    num_dbl = torch.where(torch.tensor(features[:, [0, 2, 3, 4, 5]]) >= 10, \n",
    "                          torch.tensor(1), \n",
    "                          torch.tensor(0)) # (-1, 5)\n",
    "    num_dbl = num_dbl.sum(-1) # (-1,)\n",
    "\n",
    "    dbl_dbl = torch.where(num_dbl >= 2, torch.tensor(1), torch.tensor(0)) # (-1, )\n",
    "    trpl_dbl = torch.where(num_dbl >= 3, torch.tensor(1), torch.tensor(0)) # (-1, )\n",
    "\n",
    "    dk_pts = torch.einsum('ni, ...i -> n', torch.tensor(features).float(), factors) + 1.5*dbl_dbl + 3*trpl_dbl # (-1,)\n",
    "    return dk_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothydelille/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be530af33c5424f92b22c6c25944eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['ast', 'blk', 'drb', 'fg', 'fg3', 'fg3_pct', 'fg3a', 'fg_pct', 'fga', 'ft',\\\n",
    "            'ft_pct', 'fta', 'mp', 'orb', 'pf', 'plus_minus', 'pts', 'stl', 'tov', 'trb',\\\n",
    "            'is_starter', 'is_at_home']\n",
    "\n",
    "features += abbreviations['basketball_reference_abbreviation'].tolist()\n",
    "\n",
    "all_nodes = []\n",
    "all_edges = []\n",
    "all_ts = []\n",
    "all_dk_points = []\n",
    "\n",
    "last_features = pd.DataFrame(index=player_ids, columns=features) # stores a player's last game features\n",
    "avg_feats = basic_stats.loc[(basic_stats['scope'] == 'game'), features].astype(float).fillna(0.).values.mean()\n",
    "\n",
    "last_features.loc[player_ids, :] = avg_feats # allow for a small data leakage by \n",
    "                                             # taking the average over the entire dataset\n",
    "    \n",
    "for game_id in tqdm.tqdm_notebook(basic_stats['game_id'].dropna().unique()):\n",
    "    in_scope = basic_stats[(basic_stats['game_id'] == game_id) & (basic_stats['scope'] == 'game')]\n",
    "    \n",
    "    assert len(in_scope['timestamp'].unique()) == 1, 'Different timestamp for the same game'\n",
    "    timestamp = in_scope['timestamp'].iloc[0]\n",
    "    assert in_scope['player_id'].is_unique, 'Multiple entries for the same player'\n",
    "    \n",
    "    # get last features for each player\n",
    "    feats = last_features.loc[in_scope['player_id'], :].values\n",
    "    num_players = feats.shape[0]\n",
    "    \n",
    "    # update last_features\n",
    "    current_feats = in_scope[features].astype(float).fillna(0.).values\n",
    "    last_features.loc[in_scope['player_id'], :] = current_feats\n",
    "    \n",
    "    # map player_id to node id\n",
    "    ids = in_scope['player_id'].map(tag2id).astype(int).values\n",
    "    \n",
    "    # create edges: e_ij is the concatenation of the features from player i and player j\n",
    "    edges = np.concatenate([feats[:, None, :].repeat(num_players, axis=1),\n",
    "                            feats[None, :, :].repeat(num_players, axis=0)], axis=-1)\n",
    "    # [num_players, num_players, 2*num_features]\n",
    "    # e_ijk is the k-th feature value of edge i to j\n",
    "    \n",
    "    # create nodes: n_ij will be associated with e_ij\n",
    "    nodes = np.concatenate([ids[None, :, None].repeat(num_players, axis=0), \n",
    "                            ids[:, None, None].repeat(num_players, axis=1)], axis=-1)\n",
    "    nodes = nodes.reshape(num_players*num_players, 2) \n",
    "    \n",
    "    # flatten the nodes and edges matrix / delete self connections\n",
    "    ignore_idx = np.ravel_multi_index([np.arange(num_players), np.arange(num_players)], \n",
    "                                      dims=(num_players, num_players))\n",
    "    \n",
    "    nodes = np.delete(nodes, ignore_idx, axis=0)\n",
    "    edges = edges.reshape(num_players*num_players, 2*len(features))\n",
    "    edges = np.delete(edges, ignore_idx, axis=0)\n",
    "    \n",
    "    # compute actual DraftKings points\n",
    "    pts_feats = in_scope[['pts', 'fg3', 'orb', 'ast', 'stl', 'blk', 'tov']].astype(float).fillna(0.).values\n",
    "    # [num_players, ]\n",
    "    dk_points = compute_dk_pts(pts_feats).numpy()\n",
    "    dk_points = dk_points[:, None].repeat(num_players, axis=1).reshape(num_players*num_players)\n",
    "    dk_points = np.delete(dk_points, ignore_idx, axis=0)\n",
    "    \n",
    "    # append to global lists\n",
    "    all_nodes.append(nodes)\n",
    "    all_edges.append(edges)\n",
    "    ts_array = np.full(nodes.shape[0], fill_value=timestamp)\n",
    "    all_ts.append(ts_array)\n",
    "    all_dk_points.append(dk_points)\n",
    "    \n",
    "# concatenate all games\n",
    "all_nodes = np.concatenate(all_nodes, axis=0)\n",
    "all_edges = np.concatenate(all_edges, axis=0).astype(float)\n",
    "all_ts = np.concatenate(all_ts, axis=0)\n",
    "all_dk_points = np.concatenate(all_dk_points, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pre-processed files\n",
    "nodes_csv = pd.DataFrame(all_nodes, columns=['u', 'i'])\n",
    "nodes_csv['idx'] = np.arange(len(nodes_csv)) # + 1 # begin indexing at 1\n",
    "nodes_csv['ts'] = all_ts\n",
    "nodes_csv['label'] = all_dk_points\n",
    "\n",
    "nodes_csv.to_csv('./data/ml_nba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge features\n",
    "np.save('./data/ml_nba.npy', all_edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#edges = np.load('./data/ml_nba.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('./data/ml_nba_node.npy', allow_pickle=True, mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE FEATURES\n",
    "# add general info about the player\n",
    "general_info = pd.read_csv('/Volumes/TOSHIBA EXT TIMOTHY DELILLE/GitHub/fantasy-nba/data/general_info.csv')\n",
    "general_info = general_info.dropna(subset=['id'])\n",
    "\n",
    "general_info['birth_date'] = pd.to_datetime(general_info['birth_date'])\n",
    "general_info['birth_date_ts'] = (general_info['birth_date'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "general_info['nba_debut'] = pd.to_datetime(general_info['nba_debut'])\n",
    "general_info['nba_debut_ts'] = (general_info['nba_debut'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "general_info['draft_year'] = general_info['draft_year'].str.replace(r'\\D', '')\\\n",
    "                                                       .fillna('1970')\\\n",
    "                                                       .astype(int, errors='ignore')\n",
    "general_info['draft_year_ts'] = general_info['draft_year'].apply(lambda x: pd.Timestamp(str(x)))\n",
    "general_info['draft_year_ts'] = (general_info['draft_year_ts'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "\n",
    "general_info['height_cm'] = general_info['height_cm'].astype(float)\n",
    "general_info['weight_kg'] = general_info['weight_kg'].astype(float)\n",
    "\n",
    "one_hot_teams = pd.get_dummies(general_info['draft_team'])\n",
    "general_info[one_hot_teams.columns] = one_hot_teams\n",
    "\n",
    "# one_hot_colleges = pd.get_dummies(general_info['college'])\n",
    "# general_info[one_hot_colleges.columns] = one_hot_colleges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = ['height_cm', 'weight_kg', 'birth_date_ts', 'nba_debut_ts', 'draft_year_ts']\\\n",
    "               + one_hot_teams.columns.tolist()\n",
    "\n",
    "node_feats = pd.DataFrame(index=player_ids, columns=node_features)\n",
    "\n",
    "general_info = general_info.set_index('id')\n",
    "common_players = set(player_ids).intersection(set(general_info.index))\n",
    "node_feats.loc[common_players, :] = general_info.loc[common_players, node_features]\\\n",
    "                                                 .astype(float)\\\n",
    "                                                 .fillna(0.)\\\n",
    "                                                 .values\n",
    "node_feats = node_feats.fillna(0.)\n",
    "\n",
    "np.save('./data/ml_nba_node.npy', node_feats.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/ml_nba_node.npy', np.zeros((len(player_ids), 172))) # memory_dim = 172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python train_self_supervised.py --use_memory --prefix tgn-attn --n_runs 1 --n_epoch 10 --data nba\n",
    "\n",
    "python train_supervised.py --use_memory --prefix tgn-attn --n_runs 1 --n_epoch 1 --data nba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_reddit = pd.read_csv('/Volumes/TOSHIBA EXT TIMOTHY DELILLE/GitHub/tgn/data/ml_reddit.csv', nrows=199)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_time, test_time = list(np.quantile(nodes_csv.ts, [0.70, 0.85]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1489777200.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/ml_nba_test.npy', all_edges.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.diff(nodes_csv.loc[nodes_csv['ts'] <= val_time, 'ts']) >= 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=8683370, step=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_csv.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>idx</th>\n",
       "      <th>ts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256671800</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1256671800</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1256671800</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1256671800</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1256671800</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683365</th>\n",
       "      <td>543</td>\n",
       "      <td>135</td>\n",
       "      <td>8683365</td>\n",
       "      <td>1610920800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683366</th>\n",
       "      <td>1263</td>\n",
       "      <td>135</td>\n",
       "      <td>8683366</td>\n",
       "      <td>1610920800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683367</th>\n",
       "      <td>1351</td>\n",
       "      <td>135</td>\n",
       "      <td>8683367</td>\n",
       "      <td>1610920800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683368</th>\n",
       "      <td>1376</td>\n",
       "      <td>135</td>\n",
       "      <td>8683368</td>\n",
       "      <td>1610920800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683369</th>\n",
       "      <td>1262</td>\n",
       "      <td>135</td>\n",
       "      <td>8683369</td>\n",
       "      <td>1610920800</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8683370 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            u    i      idx          ts  label\n",
       "0           1    0        0  1256671800   26.0\n",
       "1           2    0        1  1256671800   26.0\n",
       "2           3    0        2  1256671800   26.0\n",
       "3           4    0        3  1256671800   26.0\n",
       "4           5    0        4  1256671800   26.0\n",
       "...       ...  ...      ...         ...    ...\n",
       "8683365   543  135  8683365  1610920800    0.0\n",
       "8683366  1263  135  8683366  1610920800    0.0\n",
       "8683367  1351  135  8683367  1610920800    0.0\n",
       "8683368  1376  135  8683368  1610920800    0.0\n",
       "8683369  1262  135  8683369  1610920800    0.0\n",
       "\n",
       "[8683370 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>u</th>\n",
       "      <th>i</th>\n",
       "      <th>ts</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>199.0</td>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>80.331658</td>\n",
       "      <td>10033.743719</td>\n",
       "      <td>455.250719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.590508</td>\n",
       "      <td>45.259974</td>\n",
       "      <td>26.810967</td>\n",
       "      <td>253.704735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.590508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>49.500000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>10007.000000</td>\n",
       "      <td>260.041500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>10031.000000</td>\n",
       "      <td>454.686000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>148.500000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>10054.500000</td>\n",
       "      <td>657.529500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>198.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>10092.000000</td>\n",
       "      <td>850.441000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           u             i          ts  label         idx\n",
       "count  199.000000  199.000000    199.000000  199.000000  199.0  199.000000\n",
       "mean    99.000000   80.331658  10033.743719  455.250719    0.0  100.000000\n",
       "std     57.590508   45.259974     26.810967  253.704735    0.0   57.590508\n",
       "min      0.000000    1.000000  10001.000000    0.000000    0.0    1.000000\n",
       "25%     49.500000   44.000000  10007.000000  260.041500    0.0   50.500000\n",
       "50%     99.000000   80.000000  10031.000000  454.686000    0.0  100.000000\n",
       "75%    148.500000  116.500000  10054.500000  657.529500    0.0  149.500000\n",
       "max    198.000000  163.000000  10092.000000  850.441000    0.0  199.000000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_reddit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features = np.load('./data/ml_{}.npy'.format('nba'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(basic_stats):\n",
    "    u_list, i_list, ts_list, label_list = [], [], [], []\n",
    "    feat_l = []\n",
    "    idx_list = []\n",
    "\n",
    "    with open(data_name) as f:\n",
    "        s = next(f)\n",
    "        for idx, line in enumerate(f):\n",
    "            e = line.strip().split(',')\n",
    "            u = int(e[0])\n",
    "            i = int(e[1])\n",
    "\n",
    "            ts = float(e[2])\n",
    "            label = float(e[3])  # int(e[3])\n",
    "\n",
    "            feat = np.array([float(x) for x in e[4:]])\n",
    "\n",
    "            u_list.append(u)\n",
    "            i_list.append(i)\n",
    "            ts_list.append(ts)\n",
    "            label_list.append(label)\n",
    "            idx_list.append(idx)\n",
    "\n",
    "            feat_l.append(feat)\n",
    "            \n",
    "    return pd.DataFrame({'u': u_list,\n",
    "                         'i': i_list,\n",
    "                         'ts': ts_list,\n",
    "                         'label': label_list,\n",
    "                         'idx': idx_list}), np.array(feat_l)\n",
    "\n",
    "def reindex(df, bipartite=True):\n",
    "    new_df = df.copy()\n",
    "    if bipartite:\n",
    "        assert (df.u.max() - df.u.min() + 1 == len(df.u.unique()))\n",
    "        assert (df.i.max() - df.i.min() + 1 == len(df.i.unique()))\n",
    "\n",
    "        upper_u = df.u.max() + 1\n",
    "        new_i = df.i + upper_u\n",
    "\n",
    "        new_df.i = new_i\n",
    "        new_df.u += 1\n",
    "        new_df.i += 1\n",
    "        new_df.idx += 1\n",
    "    else:\n",
    "        new_df.u += 1\n",
    "        new_df.i += 1\n",
    "        new_df.idx += 1\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def run(data_name, bipartite=True):\n",
    "    Path(\"data/\").mkdir(parents=True, exist_ok=True)\n",
    "    PATH = './data/{}.csv'.format(data_name)\n",
    "    OUT_DF = './data/ml_{}.csv'.format(data_name)\n",
    "    OUT_FEAT = './data/ml_{}.npy'.format(data_name)\n",
    "    OUT_NODE_FEAT = './data/ml_{}_node.npy'.format(data_name)\n",
    "\n",
    "    df, feat = preprocess(PATH)\n",
    "    new_df = reindex(df, bipartite)\n",
    "\n",
    "    empty = np.zeros(feat.shape[1])[np.newaxis, :]\n",
    "    feat = np.vstack([empty, feat])\n",
    "\n",
    "    max_idx = max(new_df.u.max(), new_df.i.max())\n",
    "    rand_feat = np.zeros((max_idx + 1, 172))\n",
    "\n",
    "    new_df.to_csv(OUT_DF)\n",
    "    np.save(OUT_FEAT, feat)\n",
    "    np.save(OUT_NODE_FEAT, rand_feat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
